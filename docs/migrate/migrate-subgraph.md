---
sidebar_position: 2
title: Migrate from TheGraph
---

# Migrate from TheGraph

This guide walks through the steps to migrate a subgraph to Subsquid. In what follows we will convert the [Gravatar](https://github.com/graphprotocol/example-subgraph) subgraph into a squid and run it locally. Impatient readers may clone the migrated squid from the `gravatar-squid` branch of the [squid-evm-template repo](https://github.com/subsquid/squid-ethereum-template):

```bash
git clone -b gravatar-squid https://github.com/subsquid/squid-ethereum-template.git
```
and run it by following the instructions in README.

Subsquid offers batched processing and a slightly different log handling programming model, which pays off with up to a 100x increase in the indexing speed. At the same time, the concepts of the [schema file](/develop-a-squid/schema-file), code generation and automatic GraphQL API should be familiar for subgraph developers. In most cases the schema file can used by a squid as is. 

## Squid setup 

### 1. Clone template

To begin with, clone the Ethereum squid template from the [squid-ethereum-template repo](https://github.com/subsquid/squid-ethereum-template):

```bash
git clone https://github.com/subsquid/squid-ethereum-template.git
cd squid-ethereum-template
```

### 2. Copy the schema file and generate entities

The minimal template already contains a dummy `schema.graphql` file. We replace it with the subgraph's schema as is:

```gql file=schema.graphl
type Gravatar @entity {
  id: ID!
  owner: Bytes!
  displayName: String!
  imageUrl: String!
}
```

Next, we generate the entities from the schema and check the squid builds:
```bash
make codegen
make build
```

After that start the local database and generate the migrations from the generated entities:
```bash
make up
make migration
```
The migration file will appear in `db/migrations`

### Generate typings from ABI

Copy the contract ABI (`Gravity.json`) to `src/abi` and run [EVM typegen](/develop-a-squid/typegen/squid-evm-typegen):
```bash
npx squid-evm-typegen --abi=src/abi/Gravity.json --output=src/abi/Gravity.ts
```

The generated access class will be generated in `src/abi/Gravity.ts`. In particular, it will contain the boilerplate to decode the logs and the topic definitions used at the next step. 

### Subscribe to EVM logs

The core of the indexing logic is implemented in `src/processor.ts`. This is where we define which EVM logs (events) our squid will process and the batch handler for them. Squids are configured directly in the code, unlike subgraphs which require the handlers and event to be defined in the manifest file.

```ts file=src/processor.ts
import { events } from "./abi/Gravity";

const processor = new EvmBatchProcessor()
  .setDataSource({
    chain: process.env.ETHEREUM_MAINNET_WSS,
    archive: 'https://eth-test.archive.subsquid.io',
  })
  .setBlockRange({ from: 6175243 })
  .addLog('0x2E645469f354BB4F5c8a05B3b30A929361cf77eC', {
    filter: [[
      events['NewGravatar(uint256,address,string,string)'].topic,
      events['UpdatedGravatar(uint256,address,string,string)'].topic,
   ]],
    data: {
        evmLog: {
            topics: true,
            data: true,
        },
    } as const,
});
```

In the snippet above we tell the squid processor to fetch logs emitted by the contract `0x2E645469f354BB4F5c8a05B3b30A929361cf77eC` that match of the specified topics. Note that the topic filter is a double array as required by the [selector specification](https://docs.ethers.io/v5/api/utils/abi/interface/#Interface--selectors). The configuration also specifies that the indexing should start from block `6175243` onwards (when the contract was deployed).

### Transform and save the data

The processor currently doesn't do much and simply outputs the data it fetches from the archive.

Now we migrate the subgraph handlers which transform the event data into `Gravatar` objects. Instead of saving or updating gravatars one by one, `EvmBatchProcessor` receives an ordered batch of event items it is subscribed to (which can be inspected by the output). 

We start with an auxiliary function that extracts the event data from the logs using the helper classes generated by `evm-codegen` from the ABI

```ts
function extractData(evmLog: any): { id: ethers.BigNumber, owner: string, displayName: string, imageUrl: string} {
  if (evmLog.topics[0] === events['NewGravatar(uint256,address,string,string)'].topic) {
    return events['NewGravatar(uint256,address,string,string)'].decode(evmLog)
  }
  if (evmLog.topics[0] === events['UpdatedGravatar(uint256,address,string,string)'].topic) {
    return events['UpdatedGravatar(uint256,address,string,string)'].decode(evmLog)
  }
  throw new Error('Unsupported topic')
}
```

Next, we processed with a batch handler collecting the updates from a single batch of EVM logs. The update is an ordered array of items which may span multiple blocks. Each item is either an `UpdateGravatar` event or a `NewGravatar` event, as was configured in the previous step

```ts
processor.run(new TypeormDatabase(), async (ctx) => {
    const gravatars: Map<string, Gravatar> = new Map();
    for (const c of ctx.blocks) {
      for (const e of c.items) {
        if(e.kind !== "evmLog") {
          continue
        }
        const { id, owner, displayName, imageUrl } = extractData(e.evmLog)
        gravatars.set(id.toHexString(), new Gravatar({
          id: id.toHexString(),
          owner: decodeHex(owner),
          displayName,
          imageUrl
        })) 
      }
    }
    await ctx.store.save([...gravatars.values()])
});
```

The implementation is straightforward -- the newly created and/or updated gravatars are tracked by an in-memory map. The values are persistent in a single batch upsert via `cts.store.save(...)`.

### Run the API

Run 

```bash
make serve
```

and inspect the auto-generated GraphQL API using the interactive playground at `http://localhost:4350/graphql` 


## What's Next?

- Learn how to [deploy a squid to the Aquarium hosted service](/deploy-squid) for free
- Learn how to [access the contract state](/develop-a-squid/squid-processor/evm-support/#access-the-contract-state)
- Inspect a more complex [Uniswap V3 squid](https://github.com/subsquid/uniswap-squid) which tracks Uniswap V3 trading data. It was migrated from the [Uniswap V3 subgraph](https://github.com/Uniswap/v3-subgraph). It takes only a few hours to sync from scratch on a local machine.
